{
    "posts": [
        {
            "title": "The missing picture",
            "author": "Eloïse Vo",
            "image": "./public/images/The_missing_picture.png",
            "extent": {
                "southwest": [0.255368, 0.010462],
                "northeast": [0.521672, 0.386944]
            },
            "text": [
                "From (data) extraction at the edge of the human, toward an aesthetic of productive lethargy. By means of combining and analyzing unprecedented amounts of data, databases became new modes of knowing the world and knowing ourselves. Databases stabilize and materialize social forces as well as organizational and political logic. There are the results of a multitude of administrative practices, labor, scripted gestures and gendered and racialized bodies that have shaped the very material of today's algorithmic governance. While the body of workers is usually obfuscated by the myth of automation, performing artificial-artificial intelligence, I would like to trace the cognitive operations that are organized by data extraction processes.",
                "Shaping and designing behaviors, data extraction transforms the body into a sensitive captor, creating the material conditions of the exploitation of the workers feelings, sensitivity and affects. From the logarithmic table to the platform of micro-work, the project of the PhD research aims to draw a genealogy of these material inscriptions and mediating machines of labor and cognition. But in this particular case, I would like to focus on live streaming of sleeping bodies via the platform twitch or tiktoks, and this new form of “visual ASMR”. Thus, this blueprint is an attempt to map an archeology of sleeping by technical means, in today's digital and non digital environment. While fatigue studies have been determinant in the design of productive productivity in the industrial age, what is even action in an environment where everything is a data-based-monetized action ? Studying the economic and political extraction of human cognition and body, we tend to explore the concept of economy of attention toward its limit, where even non-action is monetized. Finally, we want to link this study-case to the wider concept of the wetware, to define this specific relationship between bodies and machines in our digital era. This term was used in the 80s science-fiction to define the computation logic of nature and living-being, as the structure of a snowflake for example or DNA. Referring the energy that flows and animates these non-human infrastructures, the metaphor of humidity or liquidity, embedded in the term of wetware, allow us to locate the specific role of the human in the loop, not only in the information and data production but in the creation of a network of sensitive bodies. What are the relationships that are reconfigured between the sleeping bodies and their viewers/watchers. How the specific mode of attention of the “veille” is (re)shaped by digital environment ?",
                "Finally, exploring how the metaphor of the wetware traveled from science fiction to cyberfeminism, to corporate culture, art and design, I attempt to map how these metaphors mediate the perception and rationalization of the working body. While tech companies are developing the material conditions and conceptual framework of the 'human-as-a-service' or the ' human-as-a-plugin', what are the other narratives that can derive from an ideology of techniques and organization rusted by the wetware ?",
                "By interrogating the wetware and its material condition of labor, from software to hardware, we can move beyond the so-called replacement of humans by machines towards understanding the new ways in which cognition and body are being transformed and perpetuated, not simply displaced and rendered obsolete."
            ]
        },
        {
            "title": "Points, Planes and Proxies: A Blueprint for Sensing the Multispecies City",
            "author": "Marcela Delgado Velasco",
            "image": "./public/images/Points_Planes_and_ Proxies.png",
            "extent": {
                "southwest": [0.065892, 0.803314],
                "northeast": [0.157616, 0.9756]
            },
            "text": [
                "Given the upward trend in urbanization and the alarming decline in global biodiversity, it is vital to design for urban growth that supports all life forms. The anthropocentric bias ingrained in the way we sense and view the city, however, inhibits the development of future imaginaries aimed at multi-species co-existence, and decentering the human experience as the touchstone of design praxis requires attention. This thesis aims to recalibrate the lens with which we approach future habitat integration in the design disciplines by questioning the conceptual with which urban sensing and visualization is approached, the imaginaries it amplifies and those it overlooks. How can visualization, simulation, and prediction tools be utilized to transcend the nature-culture divide and generate multi-species resolutions of the city?",
                "The Blueprint for Sensing the Multispecies City seeks to uncover the nature-culture divide as reflected in current urban species data visualization methods and challenge this construct by expressing nature’s interconnectedness with the built environment. What agents, methods and instruments bring urban biodiversity into our field of vision? What are the translations and transformations necessary for computing the living and when does the process of fixing species into immutable data become a generative act capable of describing spaces of overlap between modes of being? Lausanne will be taken as the case study to illustrate this methodology, and given that multiple actors participate in constructing the urban imaginary these questions will be described through the use of official/unofficial data sets emerging from citizen science platforms, city led initiatives, and published scientific findings.",
                "The ways in which non-human species navigate and thrive in urban landscapes have largely been ignored or underrepresented in design research and practice. Naturalists and biologists have only recently begun to take interest in the city and its life forms. This convergence in disciplinary attention provides fertile ground for investigating new frameworks that step away from conventional Modernist dichotomies that treat the urban environment as a collection of independent structures and green islands rather than as an interdependent ecology. Biodiversity is radically inclusive and spans multiple ways of being and interdependencies that can overwhelm our narrow and limited perception. To capture this complexity and mold these realities into knowable forms, reduction and abstraction is inevitable and necessary, but formulating methods that abstract the ties between objects, technologies, cities and living things can help avoid abstraction that isolates species from context and larger meaning.",
                "I’d like to propose a framework that I call “points, planes, and proxies” that represent the types of abstractions that currently support the construction of a multispecies urban imaginary in Lausanne. These methods range from spontaneous to more elaborate forms of observing and documenting biodiversity. Some modes and levels of abstraction reinforce dichotomies and participate in conceptualizing the environment as “other”, such as nature to be protected, attracted or nature to be repelled, controlled, or eliminated. Other data assemblages have the potential to register future synergies between species and the built environment.",
                "Data points scraped from the iNaturalist.org represent Lausanne’s biodiversity through three pieces of information: a picture of an individual species taken by a citizen scientist, the geolocation of where that picture was taken, and the category of species represented by the color of the point. The platform allows for others to participate in identifying the species, which in turn helps train an automated species identification tool that relies on computer vision. Crowdsourcing biodiversity data has significantly contributed to scientist’s understanding of urban biodiversity, data collection that would otherwise require expensive tools and  labor. Despite the virtues of this platform, the spatial distribution of “points” representing species are not yet operational in the context of this research because they do not express dynamics or ties between species, urban space and architecture.",
                "Planes, on the other hand, can be overlaid like tracing paper, and the intersections with the built environment emerge. In 2014 the Bureau d’études biologiques Raymond Delarze, a small team of biologists presented the city of Lausanne a comprehensive study intended to serve as a guide for designing specific objectives and conservation strategies for protecting urban biodiversity. According to the report, the effects of rapid urbanization in the 20th century led to the extinction of many highly specialized species that occupied biotopes that have now disappeared entirely. The first step in their diagnosis of the existing condition, therefore, was to draw an inventory of target species, namely species under threat of being added to the list of the disappearing. The biologists note that target species are generally rare organisms that are difficult to observe. The evolution of their population is often slow or difficult to predict, and therefore a census is not reliable for measuring the health of the network or the effectiveness of measures taken. For these reasons, target species are assigned a list of “indicators” or species that are more common and abundant and whose monitoring can provide relevant information on the health of the network.",
                "With these target species and proxies in mind, A collection of 6000 more or less precisely georeferenced and non uniformly distributed fauna and flora data points were restructured into a matrix. Once compiled into GIS this information was then used to characterize the biological content of the different sections of Lausanne’s ecological network consisting of 6 subnetworks generated by grouping closely related habitat types: Open water, Wetlands, Forest, Dry places, Agricultural land, Built-up land. From these operations continuous colored brush strokes of equal width representing biological corridors for subnetworks emerged on an urban map of Lausanne. A continuous linetype was designated to the corridors that were to be uninterrupted and a dotted linetype to those that would be supported through stepping stones. Streets and buildings were eliminated, colors were saturated, and each of the six subnetworks was assigned a color and a cute mascot when this map was made public in 2017 in the “Urban Ecological 2 Networks” brochure, to inform citizens about the importance of biodiversity and ways in which they too could participate in its conservation.",
                "The most recent version of these brushstrokes have made their way into the official Plan Directeur Communal for 2030 published at the end of 2022, expressing vague intentions for integrating biodiversity as a factor in planning decisions. In this latest version, all sub networks have been flattened into one layer and color named “ecological network.” The translucency of the layer shows the city fabric underneath, calling to mind many questions as to how this network will be resolved given the numerous intersections with buildings, private property and busy streets. The city’s latest attempt to compute biodiversity, “1,2,3 Nature”, is an open call for citizens to report sightings of twenty plants and animals, bio-indicators that are easily recognizable by non-specialists and whose presence reflects the quality of green spaces and gardens in Lausanne. Given that 24% of the city hides away in privately owned gardens, this initiative could be an attempt to fill this knowledge gap.",
                "Indicators, like proxy data, are used to measure something that cannot be easily or directly measured. In the case of the ecological corridors, the sighting of visible indicator species can stand-in for an entirely different species. This is an extremely powerful concept given its potential to crystallize ecological dependencies and allow for predictions to take place despite uncertainties. My last diagram is intended to “architecturalize” the ecological corridors by representing the indicator or known species as vertical planes that frame either side of a street perspective. Spaces between facades reference the target species that are not visible and construction lines will be drawn from these gaps to below ground level where the same sized spaces can be used to fill in their names. A few will be represented by an image that will capture the gaze. The diagram should convey the aspiration of the ecological networks to integrate habitats in the city fabric, attract target species and restore their presence in our collective imagination."
            ]
        },
        {
            "title": "Machine Dérive in a Street View Imagery (SVI) environments",
            "author": "Mikhael Johanes",
            "image": "./public/images/Machine_Derive.png",
            "extent": {
                "southwest": [0.545586, 0.718059],
                "northeast": [0.785475, 0.887698]
            },
            "text": [
                "Street view imagery (SVI) has gained more importance in urban analytics for deriving insight and informing decision-making. The appeal of the SVI is that it provides a proxy that 'mirrors' the world at the street level and provides information that can never be readable from a top-down, cartographic representation. There are growing numbers of research and urban analytics utilizing SVI data, including the cataloging or mapping urban infrastructure, measuring the city's well-being indicators, and characterizing city streetscapes (Biljecki & Ito, 2021). SVI data was also used to predict the demographic characteristic of a neighborhood by using deep learning to make connections between the demographic data and the visual information from the streets (Gebru et al., 2017), demonstrating the power of SVI, which raises concerns of many.",
                "SVI provides an immersive environment for seeing a city at the street level, pretending to mimic the experience of the streetwalkers. However, it is essentially a form of representation that encodes reality through thick technological layers: camera, sensor devices, algorithm, and interface (Anguelov et al., 2010). SVI is also a form of 'corporate surveillance' or street-level panopticon constantly watching the world (Gaines, 2019). Although such anxiety is valid and concerning, the total rejection of SVI will prove difficult and will not be productive. Instead, we could critically examine this relatively new form of representation and find possibilities of subversion by adopting the situationist term:  detournement to create 'new meaning and effect' (Pinder, 1996, p. 419). In the 1950s, Guy Debord produced a series of maps, 'The Naked City,' derived from Debord's psychogeography studies. The maps manifest the situationist idea of detournement as an act of re-appropriating the dominant mode of representation to be its very own critical medium. The cartographic map of Paris is fragmented and connected with arrows, representing the appealing or repelling forces between the agglomeration of the neighborhood. In such a way, the stable representation of the cartographic map is disrupted by human senses. While SVI is often seen as less abstracting and distancing than aerial images, it can be easily aggregated, geocoded, and transformed into big data to form a less visible yet more powerful abstraction through algorithms, machine learning, and statistical tools (Shapiro, 2018). We should be able to render these abstractions to engage critically with the SVI.",
                "What can be sensed through SVI, and how can it be sensed? This essay sketches a blueprint for Machinic Dérive to reveal SVI's potentiality for a novel form of sense. Naively drawn upon the situationist term derive, a free-form but critical drift through urban terrain, we can imagine a virtual 'machine' that autonomously drifts in the SVI world. With the logic of machine vision and made possible by the interaction in the encoded environment through the API,  a machine is programmed to wander in the SVI world while seeing, reading, and learning the urban environment. The idea is to envision an autonomous agent capable of wandering and learning an SVI environment. While most applications of such agents are oriented to navigational problems (Mirowski et al., 2018), I am focused on the capability of the agent to observe and act in the given environment. Can the machines sense the 'sudden change of the ambiance in the street and the repelling and appealing character of certain places' and follow 'the path of least resistance' to wander as the situationist describes (Debord, 1955, p. 2)? A brief reflection quickly highlights the particularity of machine senses. In urban analytics, machine perception is a term used to characterize the machine vision task that enables the characterization of urban space from a human perspective on a large scale (Biljecki & Ito, 2021). The idea is to extrapolate human perception to machine eyes through machine classification and regression. The automation of perception in SVI environments requires reliance on visual information compared to the multimodal perception of humans. The machine perceives by inferring the visual information, with the various data sources and human inputs, to predict the 'quality' of the observed environment (Shapiro, 2018). The machine's capacity to draw correlations is unprecedented, as it can draw connections from seemingly uncorrelated data (Gebru et al., 2017). Machine perceptions are a manifestation of a stack of algorithms and data used to 'judge' the quality of an urban environment.",
                "The 'appealing' and 'repelling' forces derived from machine perception are created from non-linear correlations between human judgment and various data sources, which implies different biases and tendencies. Machine Dérive through an urban environment can be seen as a form of evaluation of machine eyes, which can be used to compare different algorithms in perceiving the city. As such, Machine Dérive is not an observation of an urban environment through machinic eyes but of the 'tendency' of the machines to perceive a city from SVI representation. The over-reliance on visual information in SVI for machine perception is also fragile in a very particular way, from the classic 'generalization' problems that cause false inference outside the machine's training data (Tesla, 2016) to adversarial attacks (Moosavi-Dezfooli et al., 2017). Adversarial attacks fool the computer vision by inserting a perturbation agent into the machine's input, resulting in false inferences that question the computer vision algorithm's reliability. Various examples of adversarial attacks have been studied and explored, including visual alterations that result in the miss-classification of the signs (Eykholt et al., 2018; Gnanasambandam et al., 2021), exemplifies the vulnerabilities of machine vision in perceiving the cities. Adversarial attacks thus can be used as a defense against gathering information through the SVI environment by altering the environment's visual appearance to disturb the machine's inferencing results. This blueprint highlights the potentialities and vulnerabilities of machine sensing, which mainly operates on images, proliferated by the availability of visually rich information, such as SVI environments, through a toy experiment of Machine Dérive. Visually rich information of SVI enables machines to form perception through the correlation of various sources, from human inputs to crime data. The Machine Dérive is, therefore, a performative manifestation of the machine's perception, constantly drifting along to the preferences given by the algorithms. The reliance on visuals also highlighted some opportunities against the 'social sorting of place' (Shapiro, 2018, p. 1211) using adversarial attacks, which embodied the idea of detournement and critique of the domination of visuals in the current technological advancement.",
                "",
                "Refereces",
                "Anguelov, D., Dulong, C., Filip, D., Frueh, C., Lafon, S., Lyon, R., Ogale, A., Vincent, L., & Weaver, J. (2010). Google Street View: Capturing the World at Street Level. Computer, 43(6), 32–38. https://doi.org/10.1109/MC.2010.170",
                "Biljecki, F., & Ito, K. (2021). Street view imagery in urban analytics and GIS: A review. Landscape and Urban Planning, 215, 104217. https://doi.org/10.1016/j.landurbplan.2021.104217",
                "Debord, G. (1955). Introduction to a critique of urban geography. Les Lèvres Nues, 6(2).",
                "Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash, A., Kohno, T., & Song, D. (2018). Robust Physical-World Attacks on Deep Learning Models (arXiv:1707.08945). arXiv. https://doi.org/10.48550/arXiv.1707.08945",
                "Gaines, B. (2019). Digital Detournement: A Situationist Approach to Resisting Surveillance in the Googlized World. Exquisite Corpse: Studio Art-Based Writing Practices in the Academy, 105.",
                "Gebru, T., Krause, J., Wang, Y., Chen, D., Deng, J., Aiden, E. L., & Fei-Fei, L. (2017). Using deep learning and Google Street View to estimate the demographic makeup of neighborhoods across the United States. Proceedings of the National Academy of Sciences, 114(50), 13108–13113. https://doi.org/10.1073/pnas.1700035114",
                "Gnanasambandam, A., Sherman, A. M., & Chan, S. H. (2021). Optical Adversarial Attack (arXiv:2108.06247). arXiv. http://arxiv.org/abs/2108.06247",
                "Mirowski, P., Grimes, M., Malinowski, M., Hermann, K. M., Anderson, K., Teplyashin, D., Simonyan, K., kavukcuoglu,  koray, Zisserman, A., & Hadsell, R. (2018). Learning to Navigate in Cities Without a Map. Advances in Neural Information Processing Systems, 31. https://proceedings.neurips.cc/paper/2018/hash/e034fb6b66aacc1d48f445ddfb08da98-Abstract.html",
                "Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., & Frossard, P. (2017). Universal adversarial perturbations. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 1765–1773.",
                "Pinder, D. (1996). Subverting Cartography: The Situationists and Maps of the City. Environment and Planning A: Economy and Space, 28(3), 405–427. https://doi.org/10.1068/a280405",
                "Shapiro, A. (2018). Street-level: Google Street View's abstraction by datafication. New Media & Society, 20(3), 1201–1219. https://doi.org/10.1177/1461444816687293",
                "Tesla. (2016). A Tragic Loss. Tesla. https://www.tesla.com/blog/tragic-loss"
            ]
        },

        {
            "title": "Artificial Images with Environmental Sensibility",
            "author": "Christina Dumpioti",
            "image": "./public/images/Artificial_Images_with_Environmental_Sensibility.png",
            "extent": {
                "southwest": [0.564982, 0.134764],
                "northeast": [0.825964, 0.340048]
            },
            "text": [
                "Text-to-image technology has significantly transformed the field of computational creativity by providing a more efficient means of generating conceptual images. This advancement has opened up new avenues of design possibilities for future architectures. Implementing innovative means for image generation allows us to redirect our attention from the exigencies of notational design communication to the more purposeful task of reflection.Despite the remarkable progress made in this field, the impact of these generated images and their corresponding architectures on the environment remains crucial. How do these pixels translate to material, and how can these images embody environmental sensitivities?",
                "To address these concerns, the study presented through this blueprint explores the combination of generative (text-to-image) and analytical (simulation) methods within the context of computational environmental architecture. The workflow involves several stages, including the diffusion-generated conceptual image, depth-mapping imaging, semantic segmentation, digital model, simulation and analysis, and graphs, aiming to embed environmental awareness in our architectural designs. The power of imagery in architecture and design has been recognised as a tool to inspire creativity and communicate ideas. Recent advances in AI research enable a new wave of image creation by text-to-image models, which offer new ways of conceptualising design and approaching creativity. Visual and mental imagery can help architects and other designers see possibilities and opportunities that may not be immediately apparent. By developing a mental image of a design, designers can modify the image while improving the design or generating new ideas. The direct creation of digital images enables a fast and tangible representation of previously abstract concepts. As automation continues transforming how we create and consume images, it's essential to consider how these images impact our understanding of the physical world.",
                "To address these concerns, our study combines generative (text-to-image) and analytical (simulation) methods within the context of speculative design, which we use to raise awareness of the embedded data that these images carry. We aim to understand how generated pixels can translate into material bits and how they can bring designers closer to pressing matters related to environmental consciousness. Case Study: Methodological Steps We focus on producing images of a specific typology known as 'polykatoikia,' the typical residential typology in Greece [step01], comprising 80% of its building stock. Specifically, we concentrate on the façade of the polykatoikia as an assemblage for reconsideration while considering the environmental impact, particularly embodied and operational energy. Embodied energy refers to the energy consumed in the production, transportation, and installation of building materials, and operational energy refers to the energy consumed during the use of a building, such as heating, cooling, and lighting.",
                "The starting point of our design process involves textual prompting [step02], which provides initial designs for the polykatoikia's façade. While some images depicted a biased notion of what a modern Greek typology might be, proposing typologies with a classical and neoclassical style, other than that, the generated images were truthful to reality while also bringing a fresh perspective to the modern Greek typology. To generate our final batch of images as we utilised AI-powered image generation tools, namely Midjourney and Stable Diffusion. We employed various strategies to augment the images [step 03]: using the same prompt with a new seed or similar seed, re-prompting the image with text, blending two AI-generated images, and other times using depth map images and prompts. This last strategy involved keeping the form the same and only changing the materials using Stable Diffusion and ControlNet. While all strategies for augmenting images share similarities with parametric design, the outcomes can retain the subtleties of a final photorealistic image while allowing for more creative and unpredictable results. However, this can be challenging to control and fine-tune to achieve specific goals. The images undergo further editing [step 04] to remove any distracting elements, such as trees and plants, and to create depth-map images to aid in augmentation and segmentation. To help with the next step of region detection, we utilise edge detection, which produces a binary image where the pixels corresponding to the detected edges are white, and all other pixels are black. Edge detection and depth map images facilitate the crucial step of semantic segmentation by hand, which involves partitioning and colour codification based on material and depth categorisation. For 3d conversion modelling [step05]:, we used two distinct techniques: one approach is getting a 3d model from an automated extrusion of the segmented image of the previous step. The segmentation was linked to specific extrusion units based on a layer pipeline and colour coding, which determined the depth of the element in the Y-axis and material selection.",
                "The second study conducted involved converting the AI-generated images into depth map images. Each pixel of the grayscale depth map corresponded to a point in 3D space, and the pixel value represented the distance from that point to the reference point. The grayscale depth map was then transformed into a point cloud. The point cloud was further processed to create a mesh model with vertices, edges, and faces. The resulting relief model is then ready for further simulation related to operational expenditure. Facades in Mediterranean climates present unique challenges due to high solar radiation levels, requiring a balance between natural light and heat through shading and insulation. Our study considers the materials, orientation, form, and shading strategies during image generation that can contribute to the overall energy performance of the building. Embodied Energy [step06]: We have set up a file with specific wall assemblages with detailed material specifications for the embodied energy simulation. The simulation starts with the standard wall assembly found in the construction of polykatoikias, which is the brick cavity wall, comprised of 2 layers of bricks (of 10cm each) an airlayer inbetween, an insulation layer (2cm) in between, and two layers of plaster at the exterior and interior (2cm). We are using the EPIC dataset.",
                "Operational Energy [step 07]: We simulate the incident radiation on the façade of the building and the direct sunlight permeation on the interior as two indicators of possible operational energy expenditure. , the facade's orientation, overall form (overhangs, loggias, openings), and shading can impact the amount of natural light and heat that enters the building, which can affect the amount of energy needed for artificial lighting and HVAC systems related to the operational point. By changing and re-informing the introduced depth-map image we automatically observe how new elements inform the façade responsiveness to sun orientation. For this particular study, the analysis period was the summer and winter solstice and North orientation was defined at 30 degrees.",
                "Points for Discussion",
                "This project aims to bring attention to the importance of expanding beyond the visual realm and considering the potential impacts of the convergence of digital and physical worlds. By implementing a workflow incorporating various methodologies, we strive to transform our speculative idea into a tangible reality, emphasising the need for a critical shift in thinking. Architects have traditionally focused on material makeup for visual integration and financial feasibility. However, the increasing concern for environmental preservation is encouraging new connections beyond surface aesthetics by considering the broader impact of their designs on the environment. Our case study serves as evidence of the potential effectiveness of this approach."
            ]
        },

        {
            "title": "Sensing through a city of Peer-to-Peer connections",
            "author": "Juan Gómez",
            "image": "./public/images/Sensing_through_a_city_of_Peer-to-Peer_connections.png",
            "extent": {
                "southwest": [0.10643, 0.200876],
                "northeast": [0.220162, 0.337549]
            },
            "text": [
                "I explore digital commoning practices and their relationship to technologies that enable and support them. For instance, BitTorrent technologies enabled the exchange of files as a form of civil disobedience to post-copyright of digital objects such as music, images and books. More recent Peer-to-peer technologies such as IPFS (Interplanetary File System) are enabling the storage of files not in an addressed based manner but content based allowing for a decentralized infrastructure without a central server, challenging the current infrastructure of server-client and by extension demanding current protocols used by networked technologies such as HTTP (Hypertext Transfer Protocol) to be redefined. This allowed for projects such as FreeFoucoult 1 to exist.",
                "As part of Sensing Like a (Multipli)City course, I would like to explore how some of the technologies cited above are part of the networked fabric of human and non-human that creates the city. The city that thinks and sees has sensors for developing its techno sensibility but also needs servers (servants) to process, store and calculate data. How could a shift from client-server to peer-to-peer affect its techno sensibility? What new forms of urban commons could sprout as forms of resistance to technologies and dynamics that support/enable data extractivism in the city? In this regard, I would also like to analyse the fundamental configuration of the man-machine through the visuality of the words server and client within the discourse of informatics and also architecture.",
                "Major line of thought for Blueprint Client-server Principle as part of an economic model of extraction",
                "Client-server Principle as part of an economic model of extraction",
                "The Client-server principle that currently exists in the application layer of the internet could was key in the implementation of the infrastructure of the internet. The dot-com bubble was partly made thanks to the opening of the internet to commercial ventures but also that the technological protocols that allow the internet to exist were partially working and were then put in open standards for them to be collectively decided. Client-server principle evolved from the concept of distributed computing merged with a business model where few computers served the content to clients ( users). The so called “WEB 2.0 2” was never really recognized by Tim Bernes Lee as such, although devised as the normal evolution of an internet of participation and of blurring the roles of professionals / amateurs. creators / consumers could also be seen as a capitalist venture into central servers getting free content for their ( unpaid labour) for diffusing. GeoCities counted with millions of personal web spaces that people developed in their free time and rarely for commercial purposes but more like a free public space. It was bought by Yahoo in 2009 and closed the same year. Although this is not censorship related, the story of websites closing because of the cost of paying a server is true these days as well. Wikipedia is experimenting with IPFS to host their content the same way as it has been done with BitTorrent. Owning a server is technically challenging but if one is to be believe in Moore’s law then the cost of owning infrastructure for connection should be the next type of web.",
                "Materialisation of peer-to-peer protocols in spatial configurations",
                "Inmaterial by design, protocols structured the messages that pass on cables so that they could be read. In scaling the use of HTTP, data centres started to sprout to outsource the need of computers for companies to run their operations. Likewise, virtually HTTP allowed for HTML web sites to emerge as virtual spaces sometimes with commercial purposes but also blog of wiki style pages for communities to share their information visually. Peer-to-peer protocols such as IPFS, BitTorrent or Scuttlebut are designed to leverage the data exchange from one central server to many creating a network of nodes that act as client and servers. The economical model that backs this protocols in their application is usually through the tokenized economicas exchange bet it trough their own cryptocurrencies or by more established blockchain enabled ones such as Bitcoin or Ethereum. The aesthetical narrative of decentralization is generally used for backing up these projects as an artificial narration or counter tactic against a centralized state of the internet. Platforms such as UBER or Airbnb mediate spaces and shared resources and are creating a hybrid digital commoning that might be fruitful at first sight but long term they are just contributing to evading the mechanisms that society had put in place to create common goods. I argue that although Wikipedia could be considered as a fruitful example of digital commoning, the hybridising aspect of materialising a community manifests very rarely ( only through wikimedia meetings).",
                "Fighting the digital divide through community networks.",
                "The globalized project of connecting the whole world through a network was part of the original design of the internet's founding protocols architects but more than half of the world is disconnected or is connected in an exclusionary manner. The virtual spaces that the internet foster and not for everyone as of today, one of the main challenges is the digital literacy needed to alter these spaces. In places of the world where access is limited, western technological companies come as saviours giving up free connection however free of use of connections does not imply neutrality over connections. Indeed, the bias of connection between websites is very present. In countries like Colombia, the facebook page loads a lot faster compared to other websites. This created a bias of information. Overcoming the digital divide could be done through community networks as seen by cooperatives building their own internet connection at offering it as a service to their close peers.",
                "Data regulations are site specific ( GDPR, AI act, etc)",
                "Decentralization in governance also implies that there's not a central point of governance to relay in case of conflicts. Is it known for many that algorithms create social biases be it of racial or gender among others and the accountability of the creators of these protocols could be traced to its creators. The proposed diversified governance that peer-to-peer protocols propose comes with the flaw that the architecturing of protocols and its rules depends on consensus among users. Although Blockchain leverages some of the bureaucratic procedures of making group decisions in governance form of DAO’s, there are chances that by design some of the biases of using a protocol exclude some but also reinforce segregations. In this sense, technology amplifies the current biases through protocolary interventions. How to foster technological autonomy based on values that not only come from the west but that effectively stimulate the creation and preservation of commons?",
                "Data exchange in peer-to-peer networks",
                "Many applications promise Peer-to-peer communication as in that they allow for peers to exchange data but in most instances the exchanges happen through a central server that dispatches the messages. The type of peer to peer applications that allow direct exchange are very few but projects such as Cobox.cloud or filecoin are interesting hybrid proposals that could mediate the problem of data extraction. The problem with these applications is that most of them are still in early development and there is a big gap to install them as well.As a counter-design to corporate clouds many options currently exist and people offer the service of installing them and customized as needed. Artist & designers should not only be critical of this systems but also work closely society to imagine positive visions of how we can use information technology to support human flourishing without data extraction, the dematerialization of spatial exchanges thats exist nowadays as a place for work mostly could be reimagined by many with new experimental interactions."
            ]
        },
        {
            "title": "Emergency State Sensing Machine",
            "author": "Estefania Mompean Botias",
            "image": "./public/images/Emergency_State_Sensing_Machine.png",
            "extent": {
                "southwest": [0.310654, 0.715263],
                "northeast": [0.51112, 1.005402]
            },
            "text": [
                "The blueprint is an exercise of understanding the atmospheric, technical, and living assemblages that make up the reading of exceptional events, their observation, communication, and behaviors responding to the declaration of a state of emergency.",
                "For this purpose, relationships are traced at different scales between the planetary scale and the bodies, and vice versa. In its configuration, the gaze is focused on the reading of the architectures that serve as mediators or interfaces in a process of interfacing with the event, the assimilating, the lecture, and the response to a disruption.",
                "The blueprint traces relationships at different scales between the planetary scale and the bodies, and vice versa. Here the sentinel bodies, defined as living beings or technical devices that provide the first signs of an impending catastrophe, are explored. Sentinel comes from the Latin verb sentire ( to feel, to make sense). In this way, the blueprint also delves into the spatial capabilities, bodies, technological arrangements, and simulation processes.",
                "In a condition of Emergency Management response, architectures are becoming artifacts of a global showcase of security and climate reprogramming under the publicity of “climate-smart” devices. In this way, the purpose of the blueprint is to develop the assemblage of these sentinel architectures, which are assemblies of processes that recognize a possible event, interpret data, and activate a response through alarms when a certain threshold has been passed.",
                "Here, the Emergency Management Center enhances the central interface, becoming the key global governance architecture and reading and coordination center for the different bodies affected by an event. The building is located with its own territorial limits, and it is multi-connected to different scales that are also a response to forms of government. It is a global architecture with a central coordination room where the status of the event is monitored.",
                "To thicken Emergency assemblages on these processes, we could start to explore architectures that become the interface of the complex cosmopolitics of the event related not only to international response but also to cultural aspects of the region and to a complex relationship between beings that sense and make sense of a possible event. For this, the sentinel attentions developed by the assemblage of sentinel communities put themselves in relation to generating protocols of attention not so much for a hegemonic answer but for attention towards care, to organize answers and protocols in a collective way."
            ]
        },
        {
            "title": "Sensing Informalities of Housing in Rabat, Morocco",
            "author": "Rim Mrani",
            "image": "./public/images/Housing_in_Rabat.png",
            "extent": {
                "southwest": [0.183193, 0.692274],
                "northeast": [0.281886, 0.856452]
            },
            "text": [
                "1. Purpose, Scope, and Objectves:",
                "1.1. Purpose",
                "The purpose of this project is to create a digital database and housing observatory of incremental individual informalities at the scale of architectural-urban facades in a housing neighbourhood in Rabat-Morocco.",
                "1.2. Scope",
                "The scope of this project is to identify pa=erns and links of incremental informal transformations executed by the inhabitants and provide this dataset to the decisionmakers and policymakers to enhance the housing regulations accordingly.",
                "1.3. Objectives",
                "The objectives of this project are to carry out a human-based data analysis and a machine-based data analysis both organized through six temporalities and generate a feedback loop to be=er understand the dynamics of the incremental informalities of housing. The project aims to use technology to sense and tackle the incremental informalities in housing beyond the urban poor, and hence, to provide insights into the challenges faced by decision-makers, policymakers, and local authorities in dealing with the complexities of urban development of the housing sector. This model can be used for other cities of Morocco and Africa.",
                "2. Context and Methodology",
                "Housing is a crucial component of the urban life, and it is crucial to ensure that it is done accurately to the expectations of the dwellers. However, housing regulations are not always in concordance with the cultural practices of the local inhabitants, especially in African cities. Accordingly, this leads to the issue of spatial resistance towards the resulting inadequate housing. To address this issue, I suggest a pilot project aimed at sensing informalities on the scale of urban blocs’ architectural facades in a residential neighbourhood in Rabat-Morocco. Hence, the purpose of this project is to create a digital database that also serves as a housing observatory of informalities identifying symmetrical and repeated pa=erns of illegal transformations implemented by the inhabitants, that can afterwards be used to enhance the housing regulations based on these materialized needs. Accordingly, and based on the knowledge acquired via the course “Sensing Like a (Mul/pli)city”, this blueprint suggests two ways of sensing housing informalities. First, a human-based data analysis organized through three temporalities, namely, construc/ng (1), then filtering (2), then organising (3). Second, a machine-based (machine learning) data analysis, consequently organized through three temporalities, namely, de-construc/ng (4), then un-filtering (5), then re-organising (6).",
                "3. Human-based Data Analysis",
                "3.1. Data",
                "Secondary data includes the scanned history architectural-administrative data gathered from the urban municipality, and primary data covers the vectorized two-dimensional contemporary urban facades.",
                "3.2. Tools",
                "The tools comprise a large format scanner, the Leica RTC 360 and the FIXAR 007 - LiDAR (Light Detection and Ranging) items, and the CAD (Computer-Aided Design) software Archicad.",
                "3.3. Agents",
                "Involved agents in the human-based data analysis are the topographers supervised by the local authorities, the architects, and the CAD software technicians.",
                "3.4. Methods",
                "Starting with the construc:ng temporality (data layer), the project can be carried out by topography professionals, under the surveillance of the local authorities, using ground scanner Leica RTC 360 in restricted zones and aerial autonomous VTOL (vertical take-off and landing) FIXAR 007 fixed-wing drone in less restricted zones to generate the contemporary urban facades. After the 3D architectural data is collected through this LiDAR scanning process, CAD software technicians can intervein to the quick generation of the twodimensional urban facades via axonometric front view establishments in Archicad that can be used as a basis for the vectorization of this dataset within the same software. In parallel, scanned history architectural-administrative data gathered from the urban municipality, in charge of the authorizations, are used to construct the architectural history of the urban facades object of the study to filter the institutional informalities (driven by a financial rationale) from the individual informal transformations (driven by the inhabitants’ needs) after it is vectorized. Thus, since all data has the same binary file (DWG vector urban facades), it can be overlayed to detect the spatial informal transformations, highlighting the discrepancies and variations, which constitutes the filtering temporality (informa:on layer). Hence, since all the individual transformations are mapped within the urban facades, they can be structured in a scheme during the organizing temporality (knowledge layer) into main types and subtypes of informalities which can help understand the repeated and symmetrical pa=erns of the individual informal transformation, subject to improving the housing guidelines and regulations.",
                "4. Machine-based (Machine Learning) Data Analysis.",
                "4.1. Data",
                "Primary data is extracted in the format of a Microsoft Excel sheet and includes all the sensed informalities.",
                "4.2 Tools",
                "The tools comprise a Microsoft Excel file and the t-sne (t-distributed stochas/c neighbour embedding) algorithm.",
                "4.3 Agents",
                "Involved agents in the machine-based (machine learning) data analysis are the data analysts.",
                "4.4 Method",
                "Alone, this human-based data analysis process can be enough for sensing the informalities of housing. However, the machine-based data analysis can give a be=er understanding of the pa=erns and links of the la=er. The first step toward this be=er understanding is the deconstruc:ng temporality (data layer), where all constructed knowledge in the organizing temporality (3) is decomposed into a Microsoft Excel sheet where the vertical dataset is that of the Urban Facades (UFs), and the horizontal dataset is the that of the informalities (main, and sub). Next, the un-filtering temporality (informa:on layer) implements the t-sne, an unsupervised machine learning algorithm, as an exploratory data analysis of what our dataset can generate that can help be=er understand the pa=erns of informalities and their eventual links. The involved agent in this temporality is ought to be a data analyst. Finally, the last temporality, the re-organising (knowledge layer) visualises the understood links generated by the t-sne algorithm and hence improves the scheme produced during the organizing temporality (3).",
                "5. Feedback Loop",
                "5.1. Data",
                "Primary data covers the yearly vectorized two-dimensional contemporary urban facades.",
                "5.2 Tools",
                "The tools comprise the Leica RTC 360 and the FIXAR 007 - LiDAR items, the CAD software Archicad, the pervious Microsoft Excel file used in the machine-based (machine learning) data analysis and the t-sne (t-distributed stochastic neighbour embedding) algorithm.",
                "5.3 Agents",
                "Involved agents in the feedback loop are the topographers supervised by the local authorities, the architects, the CAD software technicians, and the data analysts.",
                "5.4 Method",
                "By repeating this process every year, a feedback loop can be generated that helps be=er understand the dynamics of the incremental informalities of housing that represent the materialised needs of the inhabitants and that can be a basis for the adaptation and improvement of the housing regulations and guidelines.",
                "6. Conclusion",
                "Indeed, this methodological project is ought to serve as a model for other cities of Morocco and Africa, as it showcases the advantages of using technology to sense and tackle the incremental informalities in housing beyond the urban poor. Indeed, the project provides insights into the challenges faced by the decision makers, policymakers, and local authorities in dealing with the complexities of urban development. Moreover, the use of cubng-edge technology and algorithms such as the RTC 360, the FIXAR 007, and the t-sne will help improve the accuracy and efficiency of data collection, analysis, and accurately understanding informal transformations of the housing sector. To summarize, this pilot project is an innovative initiative that will provide valuable insights into the challenges of the post protectorate/colonization urban development of African cities. By using a human-based data analysis doubled with a machine learning one in order to sense informalities on architectural facades, architects, topographers, data analysts, and CAD software technicians will be able to create a digital database for the decisionmakers and policymakers to improve the housing regulations."
            ]
        },

        {
            "title": "Rapa Nui",
            "author": "Chloé Joly Pottuz",
            "image": "./public/images/Rapa_Nui.png",
            "extent": {
                "southwest": [0.077752, 0.390131],
                "northeast": [0.344609, 0.656987]
            },
            "text": [
                "Rapa Nui is a small island, with a strong identity. It is located 3500 km west from Chilean coasts, in the Pacific Ocean. It is known for its stone giants, the Moaï. It has the shape of a triangle, measuring 25 km in length and 15 km in width, for an area of around 160 square km. The island is accessible by sea or by air. The Mataveri airport is the main entrance point for people coming to Rapa Nui. Erosion takes place in most parts of the island, aggravated by the natural elements such as the wind and the rain, and the free wandering animals such as horses and cows. Due to this erosion, there is almost no soil on Rapa Nui, which prevents grass from growing, as well as trees. The lack of grass and trees in turn aggravates erosion, as no roots hold the little soil in place. In the middle of the island, a eucalyptus plantation remains, unmanaged. Around 8600 inhabitants live today in Rapa Nui, mostly on the west coast of the island. Hanga Roa is the town where the majority of human activities are concentrated, therefore where most resources are consumed. Since 1995, the island’s national park is registered as a UNESCO World Heritage Site. Nowadays, Rapa Nui is facing pressure from the tourism industry, which represents the main economy of the island. In 2017, almost 120 000 people went to Rapa Nui.",
                "Rapa Nui’s building fabric is heterogeneous. Three construction periods can be noticed: ancestral, colonial, post-colonial. The current building stock requires constant maintenance and replacement, is sometimes even decaying, and doesn’t seem to be built to last. Inhabitants mostly self-build with what they can find and afford. In some aspects, they save resources because they are scarce. However, in other aspects, they seem to use resources irrationally. For example, big raw logs can often be seen displayed in front of houses as columns, but sometimes they are not even structural. In addition to wood, timber is widely used for building houses in Rapa Nui.",
                "There are two ways to get wood and timber on the island. Wood is mostly taken freely from the unmanaged eucalyptus plantation in the center of the island. Fallen trees or living ones (mostly eucalyptus) are sawn and brought to the construction site. This local procurement occurs mainly for self-builders: some hotels or public entities imported huge trunks from Chile. Timber, on the other hand, is imported from Chile, as there is no timber industry on the island. The imported timber is mostly pine, and the cost associated to importation makes construction materials expensive, although they come in limited quantities and in low quality. There is no port for unloading arriving goods from the sea, therefore a smaller barge commutes between the docks and the boat.",
                "In this context, my research will study the reasons why wood and timber are used the way they are for building in Rapa Nui. I will then investigate alternative possibilities in their procurement and uses. This research is important because today there is an inefficient use of resources on the island. This inefficiency is enhanced by cultural traditions and the local socio-economic context, and results in a damaging development of the place. Therefore, my goal is to ease a new way of building, informed by local traditions. This research is significant because the situation in Rapa Nui is not unique. In other transitioning, urbanising, isolated places, a particular way of building that is inefficient threatens their territories. This is why I aim at developing an approach to the problem that will be replicable in other parts of the world presenting similar conditions. Rapa Nui makes the ideal case-study for such an inquiry. As an extremely isolated island, it is a delimited ecosystem where we can assess more easily what comes in and what goes out. It is therefore easier to understand the conditions that produce a certain result.",
                "To conduct my research, I will focus on the building typology, the material supply chain and the cultural aspects in Rapa Nui. To examine these areas, I will conduct a physical survey of buildings on the island, study the industry records, and review the existing literature, as well as conduct interviews with the different actors in place such as self-builders, public services, construction material sellers and experts. This inquiry will produce a catalogue of constructive elements, an inventory of types, and an evaluation of procurement processes. Then, I will study the relations between the building stock production, the economics driving this production and the cultural aspects of the island. I will then assess the factors shaping these conditions, questioning which ones might remain and which ones could or should be modified. This will provide me with an understanding of the local building production system, from its construction material supply chain to its constructive solutions and spatial production. This understanding of the local building production system will allow me to produce a locally informed policy draft for Rapa Nui, regarding the management of resources, the territorial development of the island and its local identity.",
                "To investigate the material supply chain, this research will require knowledge-building about timber industry, timber construction and forestry management, through field visits and study periods with experts. These study periods will add to several fieldworks in Rapa Nui (the first one has been conducted in November 2022)."
            ]
        },
        {
            "title": "Facial Recognition Mapping",
            "author": "Roc Albalat, tallerestampa.com",
            "image": "./public/images/Facial_recognition_mapping.png",
            "extent": {
                "southwest": [0.528808, 0.38198],
                "northeast": [0.753732, 0.700066]
            },
            "text": [
                "Facial Recognition Mapping aims to provide a critical, archaeological and situated perspective on current facial recognition techniques, paying particular attention to the relations that facilitate the implementation of new regimes of hypervisibility and mass surveillance. To this end, we have mapped the main actors, resources, infrastructures, institutions, techniques and discourses that shape artificial vision applied to faces. Facial recognition is a technique that makes it possible to identify or analyse a person's face in photographs or videos, a system designed to operate without the target's knowledge and without their ability to resist because it is based on the immutable characteristics of their physique. It is not a trivial tool. Its development has contributed to the growth of the digital economy and the deployment of a global biometric surveillance device that has transformed the contemporary public sphere.",
                "The collection, storage and processing of visual data has consolidated an industrial model in which the capture and analysis of faces is one of the most lucrative sources. That's why, when it comes to mapping, we've focused on the list of private companies leading this growing market. These include China's SenseTime, which was the world's most valuable AI company in 2018, and US-based Clearview AI, which was named one of Time magazine's 100 most influential companies of the year in 2021. Major digital platforms have also released their own facial recognition models: Amazon (Rekognition), Facebook (DeepFace), Google (FaceNet) and Apple (Face ID). The area that these companies occupy in the graph is linked to the flow of financial investment that has nurtured the technological innovation sector for more than two decades through a system of start-ups and investment rounds.",
                "Around these private companies, we have diagrammed their raw material: datasets. Face recognition is one of the tools implemented through machine learning, a technique based on providing and processing large numbers of examples to automate tasks. To automate facial recognition, datasets of millions of facial images are required. Before proceeding with identification tasks, deep neural networks (AI) must be trained on a massive set of images to improve their success rates (faces in different poses, ages, genders, skin tones, expressions, and image quality). There is no standard metric for how many images are needed to train them, but in these industries it is in the millions. More images generally lead to better performance. And because better facial recognition models are more marketable, companies have an economic incentive to collect as many faces as possible. The collection of this facial data follows the same pattern that has enabled the emergence of the new big data and AI industries: the mass extraction and exploitation of other people's data for private purposes. The data, taken without consent, could fall foul of privacy laws, which is why the origin of the datasets is one of the industry's most closely guarded secrets.",
                "Capture and encoding of faces",
                "These days, it is hard to find someone without a smartphone in their pocket, a device equipped with a camera capable of interpreting where a face is in an image. The mass use of these cameras is creating a supply chain that ultimately feeds data-hungry companies. In this sense, the current selfie trend is both an exercise in communicating with friends, family and followers, and an unwitting contribution to training, testing and improving the statistical functions of the facial recognition industry. By sharing our photos on social networks, we are handing over data to developers who have an unlimited source of images of faces on the Internet, scraped through the search filters of Google, Instagram, YouTube or Flickr, in the latter case taking advantage of their Creative Commons licence. Other forms of mapping the faces of smartphone users include the popular Instagram filters or Face++ in China, which use augmented reality techniques to put on funny kitty ears or beautify the face with all kinds of digital make-up. Facial recognition technologies to unlock the latest generation of mobile phones or &quot;pay-per-selfie&quot; technologies are also becoming popular. To illustrate the relationship between these tools and the provision of facial datasets, the mapping presented here has smartphones as one of its two main sources of capture.",
                "The other source of capture represented in mapping is cameras located in physical space: airports, workplaces, sports stadiums, roads, public transport, ATMs or homes. The ubiquity of remote sensing is complemented by the abundance and sophistication of satellites and drones. China's credit system relies on more than 400 million cameras constantly monitoring the population, all connected to servers with real-time facial recognition systems. In the US and the EU, the use of these technologies in migration control is intensifying. In just a few years, the use of facial recognition has become naturalised, both at airports and at open borders, as a result of research and development programmes on biometric analysis. In Greece, the EU is funding the construction of fully militarised detention centres equipped with dystopian surveillance projects such as Centaur, which includes cameras and real-time detection systems. European police agencies such as Europol or Frontex, as well as think tanks linked to US security agencies, are favoured clients of large biometric surveillance corporations, an area in which opaque alliances between public and private actors are interwoven.",
                "Identifying people is just one application of facial recognition. It is also used to determine age and gender, estimate ethnicity or interpret emotions. Reading emotions is a field that has become widespread, even in the form of popular culture, since the research of the influential psychologist Paul Eckmann, whose terminology and classifications have become a standard for monitoring the secret passions of the human mind. This culture of interpretation is part of a long tradition of studies that have sought to measure, dissect and decipher the clues that would be inscribed on our faces. In this sense, current algorithmic predictions are heirs to the positivist ideas of Francis Galton, Cesare Lombroso or the taxonomic tables of Alphonse Bertillon, a system of coding police and forensic photography that had a major impact on criminology at the end of the 19th century. Far from the self-serving disruptiveness of his inventions, today's technologically advanced societies have merely updated and refined certain systems of power that, since the advent of photography, have been dedicated to segmenting and classifying the representation of the body through the image.",
                "Theorist Kelly A. Gates argues that there is no technically neutral form of machine vision that is free from the ambiguities, imperfections and subjective biases of human perception; that getting these systems to 'see' the face involves constructing particular ways of seeing. AI systems are designed by people with their own worldviews, and these end up informing the definition of criteria for evaluating the models. Computer scientists and digital activists Joy Buolamwini and Timnit Gebru pioneered the analysis of bias in databases, showing evidence of dysfunction in the accurate identification of dark-skinned women compared to white men. Beyond the operational flaws, the ethics of identifying (and inscribing) social constructs such as race and gender have been questioned. Because of this discriminatory impact on minorities, its impact on privacy, and its use as a commercial and police technique of mass surveillance, facial recognition has been the subject of controversy and contestation. It is for this reason that a selection of critical actors, whether from organised civil society or from the field of research, have been situated on the margins of the area of cartography. They are building topographies of knowledge about opaque biometric architectures and calling for their democratic regulation or even prohibition. Activism and the visual arts have promoted the use of all kinds of camouflage, masks and make-up in order to hack and search for the blind spot of facial recognition systems. They represent a conglomerate of knowledge and practices aimed at opening the black boxes of these technologies and questioning their omnipresence and inevitability.",
                "",
                "References",
                "Buolamwini, J.; Gebru, T. (2018). Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. Proceedings of the 1st Conference on Fairness, Accountability and Transparency, in Proceedings of Machine Learning Research 81:77-91",
                "Gates, K. (2011). Our biometric future. New York University Press.",
                "Harvey, A. (2022). Today’s Selfie Is Tomorrow’s Biometric Profile, in Arns, I., Hunger, F.,Lechner, M. House of Mirrors: Artificial Intelligence as Phantasm (79-83). Verlag Kettler",
                "Kak, A. ed. (2020). Regulating Biometrics: Global Approaches and Urgent Questions. AINow Institute.",
                "Peirano, M. (2019). El enemigo conoce el sistema. Debate"
            ]
        }
    ]
}
